# Wine Quality using 8 ML algorithms + EDA

This notebook explores the quality of red wine using a variety of machine learning algorithms, accompanied by thorough Exploratory Data Analysis (EDA). The journey includes an examination of the following algorithm categories:

1. **Linear Models:** Logistic Regression
2. **Tree-Based Models:** Decision Trees, Random Forests
3. **Support Vector Classifier:** SVC
4. **Boosting Models:** Gradient Boosting, XGBoost, Light GBM
5. **Distance-Based Models:** K-Nearest Neighbors

Each algorithm is analyzed in depth, highlighting their strengths and weaknesses, with key hyperparameters fine-tuned for optimal performance. The notebook intends to be comprehensive resource for anyone looking to apply these techniques to their own projects. 


In conclusion, the XGBoost Classifier is the best performer, with the highest test set accuracy (84.69%), followed by the Random Forest Classifier (83.75%). Ensemble approaches, in particular, show greater prediction skills, highlighting their effectiveness in classification tasks.

---

You can find the notebook on Kaggle [here](https://www.kaggle.com/code/anitarostami/wine-quality-using-8-ml-algorithms-eda).
The dataset used is from Kaggle: [Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009).
